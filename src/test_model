{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"test_model","provenance":[{"file_id":"1v1-LOhQs98ZpD3ZxgDhdEgHW_FYX4XP-","timestamp":1588573604119},{"file_id":"https://github.com/donyeun/AMLSII_19-20_SN18154195/blob/master/AMLS_II.ipynb","timestamp":1587959115442}],"collapsed_sections":["vwJSV9cfh9Q6"],"toc_visible":true,"machine_shape":"hm","authorship_tag":"ABX9TyNfT6nNIGI64jdUF0qGSoha"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"VGvcWF8Ph6Ki","colab_type":"text"},"source":["# **SemEval 2017 Task 4 - Testing Phase**\n","---\n","\n","\n","This is the last piece of code within the series of SemEval 2017 Task 4 challenge.\n","\n","In this notebook, we will evaluate the model by feeding testing data into the model."]},{"cell_type":"code","metadata":{"id":"oTTXAniWmfMi","colab_type":"code","outputId":"d258b1e2-f4b2-4385-e3b6-bcfc01d09d83","executionInfo":{"status":"ok","timestamp":1588579837084,"user_tz":-60,"elapsed":1658,"user":{"displayName":"Dony Arisandy Wiranata","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giy4RjCBJgU9A8zhT2B-AlcY_LP7-W-c59IBcPEoGQ=s64","userId":"05975001259031186418"}},"colab":{"base_uri":"https://localhost:8080/","height":54}},"source":["# mount google drive\n","from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"pe4VG6osyCiF","colab_type":"text"},"source":["# Libraries and Variables\n","\n","* Reading `config.yaml` which contains all ML parameters as well as filepaths\n","* Import all dependencies and libraries\n","\n","\n","\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"SkxFAcT8itpN","colab_type":"code","colab":{}},"source":["# load configuration file that store all the constant and parameters settings\n","import yaml\n","CONFIG_YAML_FILEPATH = '/content/drive/My Drive/public/AMLSII_19-20_SN18154195/src/config.yaml'\n","with open(CONFIG_YAML_FILEPATH, 'r') as file:\n","  cfg = yaml.safe_load(file)\n","\n","TASK_NUMBER = cfg['task_number']"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"_5LCvzjssSJf","colab_type":"code","outputId":"7db4c05d-fbce-4dbd-cf76-648a21436b5e","executionInfo":{"status":"ok","timestamp":1588579840772,"user_tz":-60,"elapsed":5327,"user":{"displayName":"Dony Arisandy Wiranata","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giy4RjCBJgU9A8zhT2B-AlcY_LP7-W-c59IBcPEoGQ=s64","userId":"05975001259031186418"}},"colab":{"base_uri":"https://localhost:8080/","height":955}},"source":["# install additional dependencies\n","! pip install -r {cfg['paths']['requirements']}\n","\n","import pandas as pd\n","import os\n","import torch\n","from tqdm import tqdm\n","import matplotlib.pyplot as plt\n","import nltk\n","import csv\n","import numpy as np\n","from torch.utils.data import DataLoader, Dataset\n","from torchtext.data import TabularDataset, Field, LabelField, BucketIterator\n","from sklearn.preprocessing import LabelEncoder\n","from ekphrasis.classes.tokenizer import SocialTokenizer\n","from ekphrasis.dicts.emoticons import emoticons\n","from ekphrasis.classes.preprocessor import TextPreProcessor"],"execution_count":3,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: tensorflow in /usr/local/lib/python3.6/dist-packages (from -r /content/drive/My Drive/public/AMLSII_19-20_SN18154195/requirements.txt (line 1)) (2.2.0rc3)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from -r /content/drive/My Drive/public/AMLSII_19-20_SN18154195/requirements.txt (line 2)) (1.0.3)\n","Requirement already satisfied: tensorboard in /usr/local/lib/python3.6/dist-packages (from -r /content/drive/My Drive/public/AMLSII_19-20_SN18154195/requirements.txt (line 3)) (2.2.1)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from -r /content/drive/My Drive/public/AMLSII_19-20_SN18154195/requirements.txt (line 4)) (3.2.1)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from -r /content/drive/My Drive/public/AMLSII_19-20_SN18154195/requirements.txt (line 5)) (4.38.0)\n","Requirement already satisfied: ekphrasis in /usr/local/lib/python3.6/dist-packages (from -r /content/drive/My Drive/public/AMLSII_19-20_SN18154195/requirements.txt (line 6)) (0.5.1)\n","Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (from -r /content/drive/My Drive/public/AMLSII_19-20_SN18154195/requirements.txt (line 7)) (3.2.5)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.6/dist-packages (from -r /content/drive/My Drive/public/AMLSII_19-20_SN18154195/requirements.txt (line 8)) (3.13)\n","Requirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from -r /content/drive/My Drive/public/AMLSII_19-20_SN18154195/requirements.txt (line 9)) (1.5.0+cu101)\n","Requirement already satisfied: wordcloud in /usr/local/lib/python3.6/dist-packages (from -r /content/drive/My Drive/public/AMLSII_19-20_SN18154195/requirements.txt (line 10)) (1.5.0)\n","Requirement already satisfied: keras-preprocessing>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow->-r /content/drive/My Drive/public/AMLSII_19-20_SN18154195/requirements.txt (line 1)) (1.1.0)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow->-r /content/drive/My Drive/public/AMLSII_19-20_SN18154195/requirements.txt (line 1)) (3.2.1)\n","Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow->-r /content/drive/My Drive/public/AMLSII_19-20_SN18154195/requirements.txt (line 1)) (1.28.1)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow->-r /content/drive/My Drive/public/AMLSII_19-20_SN18154195/requirements.txt (line 1)) (1.1.0)\n","Requirement already satisfied: scipy==1.4.1; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow->-r /content/drive/My Drive/public/AMLSII_19-20_SN18154195/requirements.txt (line 1)) (1.4.1)\n","Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorflow->-r /content/drive/My Drive/public/AMLSII_19-20_SN18154195/requirements.txt (line 1)) (0.34.2)\n","Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow->-r /content/drive/My Drive/public/AMLSII_19-20_SN18154195/requirements.txt (line 1)) (0.2.0)\n","Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow->-r /content/drive/My Drive/public/AMLSII_19-20_SN18154195/requirements.txt (line 1)) (2.10.0)\n","Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow->-r /content/drive/My Drive/public/AMLSII_19-20_SN18154195/requirements.txt (line 1)) (0.9.0)\n","Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow->-r /content/drive/My Drive/public/AMLSII_19-20_SN18154195/requirements.txt (line 1)) (0.3.3)\n","Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow->-r /content/drive/My Drive/public/AMLSII_19-20_SN18154195/requirements.txt (line 1)) (1.18.3)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow->-r /content/drive/My Drive/public/AMLSII_19-20_SN18154195/requirements.txt (line 1)) (1.12.0)\n","Requirement already satisfied: tensorflow-estimator<2.3.0,>=2.2.0rc0 in /usr/local/lib/python3.6/dist-packages (from tensorflow->-r /content/drive/My Drive/public/AMLSII_19-20_SN18154195/requirements.txt (line 1)) (2.2.0)\n","Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow->-r /content/drive/My Drive/public/AMLSII_19-20_SN18154195/requirements.txt (line 1)) (3.10.0)\n","Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow->-r /content/drive/My Drive/public/AMLSII_19-20_SN18154195/requirements.txt (line 1)) (1.6.3)\n","Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow->-r /content/drive/My Drive/public/AMLSII_19-20_SN18154195/requirements.txt (line 1)) (1.12.1)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->-r /content/drive/My Drive/public/AMLSII_19-20_SN18154195/requirements.txt (line 2)) (2018.9)\n","Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas->-r /content/drive/My Drive/public/AMLSII_19-20_SN18154195/requirements.txt (line 2)) (2.8.1)\n","Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard->-r /content/drive/My Drive/public/AMLSII_19-20_SN18154195/requirements.txt (line 3)) (1.0.1)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->-r /content/drive/My Drive/public/AMLSII_19-20_SN18154195/requirements.txt (line 3)) (2.23.0)\n","Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->-r /content/drive/My Drive/public/AMLSII_19-20_SN18154195/requirements.txt (line 3)) (46.1.3)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->-r /content/drive/My Drive/public/AMLSII_19-20_SN18154195/requirements.txt (line 3)) (1.6.0.post3)\n","Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard->-r /content/drive/My Drive/public/AMLSII_19-20_SN18154195/requirements.txt (line 3)) (0.4.1)\n","Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard->-r /content/drive/My Drive/public/AMLSII_19-20_SN18154195/requirements.txt (line 3)) (1.7.2)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard->-r /content/drive/My Drive/public/AMLSII_19-20_SN18154195/requirements.txt (line 3)) (3.2.1)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->-r /content/drive/My Drive/public/AMLSII_19-20_SN18154195/requirements.txt (line 4)) (1.2.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->-r /content/drive/My Drive/public/AMLSII_19-20_SN18154195/requirements.txt (line 4)) (0.10.0)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->-r /content/drive/My Drive/public/AMLSII_19-20_SN18154195/requirements.txt (line 4)) (2.4.7)\n","Requirement already satisfied: colorama in /usr/local/lib/python3.6/dist-packages (from ekphrasis->-r /content/drive/My Drive/public/AMLSII_19-20_SN18154195/requirements.txt (line 6)) (0.4.3)\n","Requirement already satisfied: ujson in /usr/local/lib/python3.6/dist-packages (from ekphrasis->-r /content/drive/My Drive/public/AMLSII_19-20_SN18154195/requirements.txt (line 6)) (2.0.3)\n","Requirement already satisfied: ftfy in /usr/local/lib/python3.6/dist-packages (from ekphrasis->-r /content/drive/My Drive/public/AMLSII_19-20_SN18154195/requirements.txt (line 6)) (5.7)\n","Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch->-r /content/drive/My Drive/public/AMLSII_19-20_SN18154195/requirements.txt (line 9)) (0.16.0)\n","Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from wordcloud->-r /content/drive/My Drive/public/AMLSII_19-20_SN18154195/requirements.txt (line 10)) (7.0.0)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard->-r /content/drive/My Drive/public/AMLSII_19-20_SN18154195/requirements.txt (line 3)) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard->-r /content/drive/My Drive/public/AMLSII_19-20_SN18154195/requirements.txt (line 3)) (2020.4.5.1)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard->-r /content/drive/My Drive/public/AMLSII_19-20_SN18154195/requirements.txt (line 3)) (2.9)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard->-r /content/drive/My Drive/public/AMLSII_19-20_SN18154195/requirements.txt (line 3)) (3.0.4)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->-r /content/drive/My Drive/public/AMLSII_19-20_SN18154195/requirements.txt (line 3)) (1.3.0)\n","Requirement already satisfied: cachetools<3.2,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard->-r /content/drive/My Drive/public/AMLSII_19-20_SN18154195/requirements.txt (line 3)) (3.1.1)\n","Requirement already satisfied: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard->-r /content/drive/My Drive/public/AMLSII_19-20_SN18154195/requirements.txt (line 3)) (4.0)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard->-r /content/drive/My Drive/public/AMLSII_19-20_SN18154195/requirements.txt (line 3)) (0.2.8)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from ftfy->ekphrasis->-r /content/drive/My Drive/public/AMLSII_19-20_SN18154195/requirements.txt (line 6)) (0.1.9)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->-r /content/drive/My Drive/public/AMLSII_19-20_SN18154195/requirements.txt (line 3)) (3.1.0)\n","Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<4.1,>=3.1.4->google-auth<2,>=1.6.3->tensorboard->-r /content/drive/My Drive/public/AMLSII_19-20_SN18154195/requirements.txt (line 3)) (0.4.8)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"jZwbZbXbVweZ","colab_type":"text"},"source":["## Task Logistics"]},{"cell_type":"code","metadata":{"id":"uyq_2EdrVNYL","colab_type":"code","colab":{}},"source":["# GENERAL TRAIN-TEST VARS\n","if TASK_NUMBER == 'A':\n","  train_csv_filepath = cfg['paths']['cleaned_train_a']\n","  test_csv_filepath = cfg['paths']['cleaned_test_a']\n","  saved_model_filepath = cfg['paths']['task_a_model']\n","elif TASK_NUMBER == 'B':\n","  train_csv_filepath = cfg['paths']['cleaned_train_b']\n","  test_csv_filepath = cfg['paths']['cleaned_test_b']\n","  saved_model_filepath = cfg['paths']['task_b_model']"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vwJSV9cfh9Q6","colab_type":"text"},"source":["# List of Hyperparameter Trials"]},{"cell_type":"code","metadata":{"id":"icXEiVRXVXW6","colab_type":"code","colab":{}},"source":["params = {\n","    'vocab': {\n","        'batch_size' : [32, 64],\n","\t      'max_vocab_size' : [50000, 100000],\n","  \t    'pretrained_embedding': [{\n","            'url' : 'https://dl.fbaipublicfiles.com/fasttext/vectors-english/crawl-300d-2M.vec.zip',\n","            'filepath': './crawl-300d-2M.vec',\n","            'embedding_dim': 300,\n","        },{\n","            'url' : 'http://nlp.stanford.edu/data/glove.twitter.27B.zip',\n","            'filepath': './glove.twitter.27B.200d.txt',\n","            'embedding_dim' : 200,\n","        },],\n","        'preprocessing' : [{\n","            'normalize' : ['url', 'email', 'percent', 'money', 'phone', 'user',\n","                'time', 'date', 'number'],\n","            'annotate' : ['hashtag', 'allcaps', 'elongated', 'repeated', 'emphasis', 'censored'],\n","            'spell_correct_elong' : True,\n","            'to_lowercase': True,    \n","        },\n","        ]\n","    },\n","    'nn': { \n","          'hidden_dim': [128, 256],\n","          'n_layers': [2, 3],\n","          'is_bidirectional': [True],\n","          'dropout': [0.5, 0.8],\n","          'n_epochs': [20],\n","    }\n","}"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"D0KvskijQ9H9","colab_type":"text"},"source":["## Build Torch Dataset\n"]},{"cell_type":"code","metadata":{"id":"h-_FIEeLyTFM","colab_type":"code","colab":{}},"source":["# read csv file as torchtext's TabularDataset\n","def csv_to_tabular_dataset(filepath, fields):\n","  tabular_daset = TabularDataset(\n","      path=filepath,\n","      fields = fields,\n","      format='tsv',\n","      skip_header=True\n","  )\n","  return tabular_daset"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wpIHw_3YdSAn","colab_type":"text"},"source":["## RNN-LSTM"]},{"cell_type":"markdown","metadata":{"id":"2TsmpHiydeyr","colab_type":"text"},"source":["three layers:\n","1. embedding layer (transform one-hot encoding vector into a dense embedding vector)\n","2. RNN\n","3. linear layer (output)"]},{"cell_type":"code","metadata":{"id":"Xo_SPYGZdWuq","colab_type":"code","colab":{}},"source":["import torch.nn as nn\n","import time\n","import requests, zipfile, io\n","from pathlib import Path\n","from torchtext.vocab import Vectors\n","import torch.optim as optim\n","import dill\n","\n","class RNN(nn.Module):\n","  def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers,\n","               bidirectional, dropout, pad_idx):\n","    super().__init__()\n","    self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=pad_idx)\n","    # self.rnn = nn.RNN(embedding_dim, hidden_dim)\n","    self.rnn = nn.LSTM(embedding_dim,\n","                       hidden_dim,\n","                       num_layers=n_layers,\n","                       bidirectional=bidirectional,\n","                       dropout=dropout,\n","                       )\n","    self.fully_connected = nn.Linear(hidden_dim*2, output_dim)\n","    self.dropout = nn.Dropout(dropout)\n","\n","  def forward(self, text, text_length):\n","    # text dimention is [sentence len, batch size]\n","    \n","    # embedded dimention is [sentence len, batch size, embedding_dim]\n","    embedded = self.dropout(self.embedding(text))\n","\n","    # pack the sequence\n","    packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, text_length)\n","    # print('packed_embedded:')\n","    # print(packed_embedded)\n","    packet_output, (hidden, cell) = self.rnn(packed_embedded)\n","\n","    # unpack the sequence\n","    output, output_length = nn.utils.rnn.pad_packed_sequence(packet_output)\n","\n","    # output dimention is [sentence len, batch size, hidden dim * num directions]\n","    # output over padding tokens are zero tensors\n","\n","    # hidden dimension is [num layers*num directions, batch size, hidden dim]\n","    # cell dimension is also [num layers*num directions, batch size, hidden dim]\n","\n","    #concat the final forward (hidden[-2,:,:]) and backward (hidden[-1,:,:]) hidden layers\n","    #and apply dropout\n","\n","    # hidden dimension is [batch size, hid dim*num directions]\n","    hidden = self.dropout(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim=1))\n","    \n","    return self.fully_connected(hidden)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"eWbAXYOsr68C","colab_type":"code","colab":{}},"source":["def count_model_params(model):\n","  # number of parameters that are trainable\n","  return sum(p.numel() for p in model.parameters() if p.requires_grad)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"_5cEu9fAwixJ","colab_type":"code","colab":{}},"source":["from sklearn.metrics import confusion_matrix, accuracy_score, recall_score, precision_score, f1_score\n","def calculate_performance(y, preds):\n","  # get the index of the max probability \n","  Y_pred = preds.argmax(dim = 1, keepdim = True).squeeze(1)\n","  Y_pred = Y_pred.detach().cpu().clone().numpy()\n","  \n","  Y_true = y.detach().cpu().clone().numpy()\n","\n","  acc = accuracy_score(Y_true, Y_pred)\n","  rec = recall_score(Y_true, Y_pred, average='macro')\n","  prec= precision_score(Y_true, Y_pred, average='macro')\n","  f1  = f1_score(Y_true, Y_pred, average='macro')\n","  return acc, rec, prec, f1, Y_true, Y_pred\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cVfC0pFjZFm-","colab_type":"text"},"source":["# Test the Model"]},{"cell_type":"code","metadata":{"id":"LrCjCa6atiEY","colab_type":"code","colab":{}},"source":["def evaluate(model, iterator, criterion):   \n","    epoch_loss = 0\n","    epoch_acc = 0\n","    epoch_rec = 0\n","    epoch_prec = 0\n","    epoch_f1 = 0\n","    \n","    Y_true = []\n","    Y_pred = []\n","    model.eval()\n","\n","    with torch.no_grad():\n","    \n","        for batch in iterator:\n","            text, text_length = batch.text\n","            predictions = model(text, text_length).squeeze(1)\n","            actuals = batch.sentiment\n"," \n","            loss = criterion(predictions, batch.sentiment.long())\n","            \n","            acc, rec, prec, f1, y_true, y_pred = calculate_performance(batch.sentiment, predictions)\n","            Y_true = np.concatenate([Y_true,y_true])\n","            Y_pred = np.concatenate([Y_pred,y_pred])\n","\n","            epoch_loss += loss.item()\n","            epoch_acc += acc.item()\n","            epoch_rec += rec.item()\n","            epoch_prec += prec.item()\n","            epoch_f1 += f1.item()\n","\n","            avg_loss = epoch_loss / len(iterator)\n","            avg_acc = epoch_acc / len(iterator)\n","            avg_rec = epoch_rec / len(iterator)\n","            avg_prec = epoch_prec / len(iterator)\n","            avg_f1 = epoch_f1 / len(iterator)\n","    return avg_loss, avg_acc, avg_rec, avg_prec, avg_f1, Y_true, Y_pred"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"gKN38al_sawS","colab_type":"code","colab":{}},"source":["params = {\n","    'vocab': {\n","        'batch_size' : [32, 64],\n","\t      'max_vocab_size' : [50000, 100000],\n","  \t    'pretrained_embedding': [{\n","            'url' : 'https://dl.fbaipublicfiles.com/fasttext/vectors-english/crawl-300d-2M.vec.zip',\n","            'filepath': './crawl-300d-2M.vec',\n","            'embedding_dim': 300,\n","        },{\n","            'url' : 'http://nlp.stanford.edu/data/glove.twitter.27B.zip',\n","            'filepath': './glove.twitter.27B.200d.txt',\n","            'embedding_dim' : 200,\n","        },],\n","        'preprocessing' : [{\n","            'normalize' : ['url', 'email', 'percent', 'money', 'phone', 'user',\n","                'time', 'date', 'number'],\n","            'annotate' : ['hashtag', 'allcaps', 'elongated', 'repeated', 'emphasis', 'censored'],\n","            'spell_correct_elong' : True,\n","            'to_lowercase': True,    \n","        },\n","        ]\n","    },\n","    'nn': { \n","          'hidden_dim': [128, 256],\n","          'n_layers': [2, 3],\n","          'is_bidirectional': [True],\n","          'dropout': [0.5, 0.8],\n","          'n_epochs': [20],\n","    }\n","}"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"m1Gz0yuLnjl2","colab_type":"code","colab":{}},"source":["import torch.nn as nn\n","import time\n","import requests, zipfile, io\n","from pathlib import Path\n","from torchtext.vocab import Vectors\n","import torch.optim as optim\n","import dill\n","\n","class RNN(nn.Module):\n","  def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim, n_layers,\n","               bidirectional, dropout, pad_idx):\n","    super().__init__()\n","    self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=pad_idx)\n","    # self.rnn = nn.RNN(embedding_dim, hidden_dim)\n","    self.rnn = nn.LSTM(embedding_dim,\n","                       hidden_dim,\n","                       num_layers=n_layers,\n","                       bidirectional=bidirectional,\n","                       dropout=dropout,\n","                       )\n","    self.fully_connected = nn.Linear(hidden_dim*2, output_dim)\n","    self.dropout = nn.Dropout(dropout)\n","\n","  def forward(self, text, text_length):\n","    # text dimention is [sentence len, batch size]\n","    \n","    # embedded dimention is [sentence len, batch size, embedding_dim]\n","    embedded = self.dropout(self.embedding(text))\n","\n","    # pack the sequence\n","    packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, text_length)\n","    # print('packed_embedded:')\n","    # print(packed_embedded)\n","    packet_output, (hidden, cell) = self.rnn(packed_embedded)\n","\n","    # unpack the sequence\n","    output, output_length = nn.utils.rnn.pad_packed_sequence(packet_output)\n","\n","    # output dimention is [sentence len, batch size, hidden dim * num directions]\n","    # output over padding tokens are zero tensors\n","\n","    # hidden dimension is [num layers*num directions, batch size, hidden dim]\n","    # cell dimension is also [num layers*num directions, batch size, hidden dim]\n","\n","    #concat the final forward (hidden[-2,:,:]) and backward (hidden[-1,:,:]) hidden layers\n","    #and apply dropout\n","\n","    # hidden dimension is [batch size, hid dim*num directions]\n","    hidden = self.dropout(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim=1))\n","    \n","    return self.fully_connected(hidden)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"HlIQyHYFqy6m","colab_type":"code","colab":{}},"source":["def generate_text_processor(preprocessing_params):\n","  text_processor = TextPreProcessor(\n","    # normalized these terms (ex: \"google.com\" into \"<url>\")\n","    normalize = preprocessing_params['normalize'],\n","\n","    # annotate these terms (ex: \"#win\" into [\"<hashtag>\", \"win\", \"</hashtag>\"])\n","    annotate = preprocessing_params['annotate'],\n","    fix_html=True,\n","    segmenter = 'twitter',\n","    corrector='twitter',\n","    unpack_hashtags=True,\n","    unpack_contractions=True,\n","    spell_correct_elong=preprocessing_params['spell_correct_elong'],\n","    tokenizer = SocialTokenizer(lowercase=preprocessing_params['to_lowercase']).tokenize,\n","    dicts = [emoticons]\n","  )\n","  return text_processor\n","\n","def custom_tokenizer(example):\n","  return text_processor.pre_process_doc(example)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"xL9YB1Txmqms","colab_type":"code","colab":{}},"source":["def build_torch_dataset(csv_filepath, fields, is_training_data=True):\n","\tbatch_size = 64\n","\tmax_vocab_size = 50000\n","\tdevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n"," \n","\tdata = csv_to_tabular_dataset(\n","\t  csv_filepath,\n","\t  fields = fields,\n","\t)\n","\tif not is_training_data:\n","\t\t# split into batches\n","\t\tempty, empty, test_iterator = BucketIterator.splits(\n","\t\t\t\t(None, None, data), \n","\t\t\t\tbatch_sizes = (None, None, batch_size),\n","\t\t\t\tsort_key=lambda x: len(x.text),\n","\t\t\t\tsort_within_batch = True,\n","\t\t\t\tdevice = device)\n","\t\treturn test_iterator"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"EdHaQTiSxsrH","colab_type":"code","outputId":"f2f5501b-dee8-415a-9033-80b66bf6af62","executionInfo":{"status":"ok","timestamp":1588579852990,"user_tz":-60,"elapsed":17467,"user":{"displayName":"Dony Arisandy Wiranata","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Giy4RjCBJgU9A8zhT2B-AlcY_LP7-W-c59IBcPEoGQ=s64","userId":"05975001259031186418"}},"colab":{"base_uri":"https://localhost:8080/","height":514}},"source":["def load_checkpoint(cfg, filepath):\n","  # load the model and params\n","  checkpoint = torch.load(filepath)\n","\n","  model = checkpoint['model']\n","  model.load_state_dict(checkpoint['state_dict'])\n","\n","\t# save the Field(s)\n","  with open(cfg['paths']['fields']['row_num'],\"rb\")as f:\n","      ROW_NUM = dill.load(f)\n","  with open(cfg['paths']['fields']['text'],\"rb\")as f:\n","      TEXT = dill.load(f)\n","  with open(cfg['paths']['fields']['sentiment'],\"rb\")as f:\n","      SENTIMENT = dill.load(f)\n","  fields = [('row_num', ROW_NUM), ('text', TEXT), ('sentiment', SENTIMENT)]\n","\n","  for parameter in model.parameters():\n","    parameter.requires_grad = False\n","  return model, fields, ROW_NUM, TEXT, SENTIMENT\n","\n","\n","import seaborn as sn\n","\n","def generate_confusion_matrix(Y_true, Y_pred, labels, normalize=None):\n","  cm = confusion_matrix(Y_true, Y_pred, normalize=normalize)\n","  fig = plt.figure()\n","  ax = fig.add_subplot(111)\n","  cax = ax.matshow(cm, cmap=plt.cm.get_cmap('Blues', 6))\n","  fig.colorbar(cax)\n","  ax.set_xticklabels([''] + labels, rotation=45)\n","  ax.set_yticklabels([''] + labels)\n","  plt.xlabel('Predicted')\n","  plt.ylabel('True')\n","  plt.show()\n","  \n","def execute_testing_process(model, test_iterator, fields, ROW_NUM, TEXT, SENTIMENT):\n","  criterion = nn.CrossEntropyLoss()\n","\n","  test_loss, test_acc, test_rec, test_prec, test_f1, test_Y_true, test_Y_pred = evaluate(model, test_iterator, criterion)\n","  print(f'Test Loss: {test_loss:.3f}')\n","  print(f'Test Acc : {test_acc*100:.2f}%')\n","  print(f'Test Rec : {test_rec*100:.2f}%')\n","  print(f'Test Prec: {test_prec*100:.2f}%')\n","  print(f'Test F1  : {test_f1*100:.2f}%')\n","\n","  num_classes = len(set(test_Y_true))\n","  print(num_classes)\n","  labels = []\n","  for i in range(num_classes):\n","    labels.append(SENTIMENT.vocab.itos[i])\n","    \n","  generate_confusion_matrix(test_Y_true, test_Y_pred, labels, normalize='true')\n","\n","\n","# load the best model architecture, params and weights gained from training process\n","model, fields, ROW_NUM, TEXT, SENTIMENT = load_checkpoint(cfg, saved_model_filepath)\n","\n","# text_processor will be used inside the custom_tokenizer\n","text_processor = generate_text_processor(params['vocab']['preprocessing'][0])\n","test_iterator = build_torch_dataset(test_csv_filepath, fields, is_training_data=False)\n","execute_testing_process(model, test_iterator, fields, ROW_NUM, TEXT, SENTIMENT)"],"execution_count":15,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n","  import pandas.util.testing as tm\n"],"name":"stderr"},{"output_type":"stream","text":["Reading twitter - 1grams ...\n","Reading twitter - 2grams ...\n","Reading twitter - 1grams ...\n","Test Loss: 0.588\n","Test Acc : 73.16%\n","Test Rec : 75.23%\n","Test Prec: 74.61%\n","Test F1  : 70.71%\n","2\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 2 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"DrQBNeZZtQ_L","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}